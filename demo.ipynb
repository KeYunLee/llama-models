{"cells":[{"cell_type":"markdown","metadata":{"id":"Otbl2sCtd2eq"},"source":["# 掛載google drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31153,"status":"ok","timestamp":1727412466820,"user":{"displayName":"李克耘","userId":"07893560853012048440"},"user_tz":-480},"id":"YLfqTyMj0nml","outputId":"d65afa3a-8f68-4d8b-ccea-a296ac85592c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%matplotlib inline\n","\n","import os\n","from glob import glob\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"MCqhrcwOeMu5"},"source":["# 安裝llama套件"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7429,"status":"ok","timestamp":1727412506386,"user":{"displayName":"李克耘","userId":"07893560853012048440"},"user_tz":-480},"id":"LRDy_qbO0uEA","outputId":"574d69c4-8316-42cc-e5a9-3f3da26f4922"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting llama-stack\n","  Downloading llama_stack-0.0.36-py3-none-any.whl.metadata (5.2 kB)\n","Collecting blobfile (from llama-stack)\n","  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n","Collecting fire (from llama-stack)\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting httpx (from llama-stack)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from llama-stack) (0.24.7)\n","Collecting llama-models>=0.0.36 (from llama-stack)\n","  Downloading llama_models-0.0.36-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.10/dist-packages (from llama-stack) (3.0.47)\n","Collecting python-dotenv (from llama-stack)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.9.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.32.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from llama-stack) (13.8.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from llama-stack) (2.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.36->llama-stack) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.36->llama-stack) (3.1.4)\n","Collecting tiktoken (from llama-models>=0.0.36->llama-stack)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from llama-models>=0.0.36->llama-stack) (10.4.0)\n","Collecting pycryptodomex>=3.8 (from blobfile->llama-stack)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (2.2.3)\n","Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (4.9.4)\n","Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama-stack) (3.16.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llama-stack) (1.16.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (2024.8.30)\n","Collecting httpcore==1.* (from httpx->llama-stack)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-stack) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-stack)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (24.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->llama-stack) (4.12.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit->llama-stack) (0.2.13)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llama-stack) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->llama-stack) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llama-stack) (3.3.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->llama-stack) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->llama-stack) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-stack) (1.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->llama-models>=0.0.36->llama-stack) (2.1.5)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-models>=0.0.36->llama-stack) (2024.9.11)\n","Downloading llama_stack-0.0.36-py3-none-any.whl (223 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.2/223.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_models-0.0.36-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=64d3fcccea3d0b40a79f2355ad9bf2c7a30e991ec1e87873cb7d812d51567e01\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built fire\n","Installing collected packages: python-dotenv, pycryptodomex, h11, fire, tiktoken, httpcore, blobfile, llama-models, httpx, llama-stack\n","Successfully installed blobfile-3.0.0 fire-0.6.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 llama-models-0.0.36 llama-stack-0.0.36 pycryptodomex-3.20.0 python-dotenv-1.0.1 tiktoken-0.7.0\n"]}],"source":["# Option - I: Uncomment the next line if you want to install via pip.\n","!pip install llama-stack"]},{"cell_type":"markdown","metadata":{"id":"p7kw1wY7eP64"},"source":["# Find models list"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1064,"status":"ok","timestamp":1727412594675,"user":{"displayName":"李克耘","userId":"07893560853012048440"},"user_tz":-480},"id":"2KnEtdMi0Aj3","outputId":"027e1030-c143-4bf0-964e-2e19f8d62518"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------+------------------------------------------+----------------+\n","\u001b[1m\u001b[97m| Model Descriptor                 | HuggingFace Repo                         | Context Length |\u001b[0m\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-8B                      | meta-llama/Llama-3.1-8B                  | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-70B                     | meta-llama/Llama-3.1-70B                 | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-405B:bf16-mp8           | meta-llama/Llama-3.1-405B                | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-405B                    | meta-llama/Llama-3.1-405B-FP8            | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-405B:bf16-mp16          | meta-llama/Llama-3.1-405B                | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-8B-Instruct             | meta-llama/Llama-3.1-8B-Instruct         | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-70B-Instruct            | meta-llama/Llama-3.1-70B-Instruct        | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-405B-Instruct:bf16-mp8  | meta-llama/Llama-3.1-405B-Instruct       | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-405B-Instruct           | meta-llama/Llama-3.1-405B-Instruct-FP8   | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.1-405B-Instruct:bf16-mp16 | meta-llama/Llama-3.1-405B-Instruct       | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-1B                      | meta-llama/Llama-3.2-1B                  | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-3B                      | meta-llama/Llama-3.2-3B                  | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-11B-Vision              | meta-llama/Llama-3.2-11B-Vision          | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-90B-Vision              | meta-llama/Llama-3.2-90B-Vision          | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-1B-Instruct             | meta-llama/Llama-3.2-1B-Instruct         | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-3B-Instruct             | meta-llama/Llama-3.2-3B-Instruct         | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-11B-Vision-Instruct     | meta-llama/Llama-3.2-11B-Vision-Instruct | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama3.2-90B-Vision-Instruct     | meta-llama/Llama-3.2-90B-Vision-Instruct | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama-Guard-3-11B-Vision         | meta-llama/Llama-Guard-3-11B-Vision      | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama-Guard-3-1B:int4-mp1        | meta-llama/Llama-Guard-3-1B-INT4         | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama-Guard-3-1B                 | meta-llama/Llama-Guard-3-1B              | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama-Guard-3-8B                 | meta-llama/Llama-Guard-3-8B              | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama-Guard-3-8B:int8-mp1        | meta-llama/Llama-Guard-3-8B-INT8         | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Prompt-Guard-86M                 | meta-llama/Prompt-Guard-86M              | 128K           |\n","+----------------------------------+------------------------------------------+----------------+\n","| Llama-Guard-2-8B                 | meta-llama/Llama-Guard-2-8B              | 4K             |\n","+----------------------------------+------------------------------------------+----------------+\n"]}],"source":["!llama model list"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66619,"status":"ok","timestamp":1727412746971,"user":{"displayName":"李克耘","userId":"07893560853012048440"},"user_tz":-480},"id":"05CEWiUM0GAz","outputId":"91c7ad2e-f94f-48ad-a208-71935cb03479"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please provide the signed URL you received via email (e.g., https://llama3-1.llamameta.net/*?Policy...): \n","^C\n"]}],"source":["!llama model download --source meta --model-id Llama3.2-3B"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ua82tiH0bQR"},"outputs":[],"source":["!pip install llama-toolchain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0fNY3Dj2CZx"},"outputs":[],"source":["!pip install torch fairscale fire blobfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkH82QZT4ErJ"},"outputs":[],"source":["!bash ./demo.sh"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"elapsed":41571,"status":"ok","timestamp":1727416977762,"user":{"displayName":"李克耘","userId":"07893560853012048440"},"user_tz":-480},"id":"k6DFnu5cESgE","outputId":"2b596e76-ac1a-4541-e9f9-ba0eb70b7b80"},"outputs":[{"data":{"text/html":["<style>\n","*{\n","\toutline:none;\n","}\n","code{\n","\tdisplay:inline-block;\n","\tpadding:5px 10px;\n","\tbackground: #444;\n","\tborder-radius: 4px;\n","\twhite-space: pre-wrap;\n","\tposition:relative;\n","\tcolor:white;\n","}\n",".copy-code-button{\n","\tfloat:right;\n","\tbackground:#333;\n","\tcolor:white;\n","\tborder: none;\n","\tmargin: 0 0 0 10px;\n","\tcursor: pointer;\n","}\n","p, li{\n","\tmax-width:700px;\n","}\n",".choices{\n","\tdisplay:flex;\n","\tflex: 1 0 auto;\n","}\n",".choice-section{\n","\tborder:solid 1px #555;\n","\tborder-radius: 4px;\n","\tmin-width:300px;\n","\tmargin: 10px 15px 0 0;\n","\tpadding: 0 15px 15px 15px ;\n","}\n",".button{\n","\tpadding: 10px 15px;\n","\tbackground:#333;\n","\tborder-radius: 4px;\n","\tborder:solid 1px #555;\n","\tcolor:white;\n","\tfont-weight:bold;\n","\tcursor:pointer;\n","}\n",".pill{\n","\tpadding:2px 4px;\n","\tborder-radius: 100px;\n","\tbackground-color:#e65858;\n","\tfont-size:12px;\n","\tfont-weight:bold;\n","\tmargin: 0 15px;\n","\tcolor:white;\n","}\n","</style>\n","<details class=\"choice-section\">\n","\t<summary style=\"cursor:pointer\">\n","\t\t<h3 style=\"display:inline-block;margin-top:15px\">⚙️ Client machine configuration<span class=\"pill\">Required</span></h3>\n","\t</summary>\n","\t<p>Don't worry, you only have to do this <b>once per client machine</b>.</p>\n","\t<ol>\n","\t\t<li>Download <a href=\"https://developers.cloudflare.com/argo-tunnel/getting-started/installation\">Cloudflared (Argo Tunnel)</a>, then copy the absolute path of the cloudflare binary</li>\n","\t\t<li>Now, you have to append the following to your SSH config file (usually under ~/.ssh/config), and make sure you replace the placeholder with the path you copied in Step 1:</li>\n","\t</ol>\n","\t<code>Host *.trycloudflare.com\n","\tHostName %h\n","\tUser root\n","\tPort 22\n","\tProxyCommand &ltPUT_THE_ABSOLUTE_CLOUDFLARE_PATH_HERE&gt access ssh --hostname %h\n","\t</code>\n","</details>\n","<div class=\"choices\">\n","\t<div class=\"choice-section\">\n","\t\t<h4>SSH Terminal</h4>\n","\t\t<p>To connect using your terminal, type this command:</p>\n","\t\t<code>ssh gain-judge-keith-pci.trycloudflare.com</code>\n","\t</div>\n","\t<div class=\"choice-section\">\n","\t\t<h4>VSCode Remote SSH</h4>\n","\t\t<p>You can also connect with VSCode Remote SSH (Ctrl+Shift+P and type \"Connect to Host...\"). Then, paste the following hostname in the opened command palette:</p>\n","\t\t<code>gain-judge-keith-pci.trycloudflare.com</code>\n","\t</div>\n","</div>\n","\n","<script>\n","// Copy any string\n","function fallbackCopyTextToClipboard(text) {\n","  var textArea = document.createElement(\"textarea\");\n","  textArea.value = text;\n","  \n","  // Avoid scrolling to bottom\n","  textArea.style.top = \"0\";\n","  textArea.style.left = \"0\";\n","  textArea.style.position = \"fixed\";\n","\n","  document.body.appendChild(textArea);\n","  textArea.focus();\n","  textArea.select();\n","\n","  try {\n","    var successful = document.execCommand('copy');\n","    var msg = successful ? 'successful' : 'unsuccessful';\n","    console.log('Fallback: Copying text command was ' + msg);\n","  } catch (err) {\n","    console.error('Fallback: Oops, unable to copy', err);\n","  }\n","\n","  document.body.removeChild(textArea);\n","}\n","\n","// Show the copy button with every code tag\n","document.querySelectorAll('code').forEach(function (codeBlock) {\n","\tconst codeToCopy= codeBlock.innerText;\n","\tvar pre = document.createElement('pre');\n","\tpre.innerText = codeToCopy;\n","    var button = document.createElement('button');\n","    button.className = 'copy-code-button';\n","    button.type = 'button';\n","    button.innerText = 'Copy';\n","\tbutton.onclick = function(){\n","\t\tfallbackCopyTextToClipboard(codeToCopy);\n","\t\tbutton.innerText = 'Copied'\n","\t\tsetTimeout(()=>{\n","\t\t\tbutton.innerText = 'Copy'\n","\t\t},2000)\n","\t}\n","\tcodeBlock.children = pre;\n","\tcodeBlock.prepend(button)\n","});\n","</script>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Install colab_ssh on google colab\n","!pip install colab_ssh --upgrade --quiet\n","from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","launch_ssh_cloudflared(password=\"1234Qwer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSUNzAJ1EgKU"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
